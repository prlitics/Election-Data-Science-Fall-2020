---
title: "Inference II"
subtitle: "Election Data Science"  
author: 
  - "Peter Licari"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#1381B0",
  secondary_color = "#FF961C",
  inverse_header_color = "#FFFFFF",
  text_font_google = google_font("Poppins")
)

xaringanExtra::use_xaringan_extra()
library(tidyverse)
library(kableExtra)
```

```{css, echo=FALSE}
pre code, pre, code {
  white-space: pre !important;
  height: 100px !important;}
```

--
class: center, middle
# I'm proud of you.

---
# What we've learned.
--

- Programming languages are just that--*languages*
  - So is maths, for that matter.
- Computers are the dumbest kind of magic.
- Data **never** speak for themselves.
- As data professionals, you have an inherent obligation to be ethical in your handling of data and in your presentation of your results. Every point is a *person.* Every narrative impacts **real people.**
- Analytical procedures never make anything *objective.* Objectivity is not a thing that actually exists. (Or, at the very least, is not attainable by us mere mortals.)
- All data are artifacts of the time, place, people, and culture they are generated from. There meanings are laden with this context.

---
# What we're learning today:
--
**More Advanced causal inference**
--

* Lab Experiments
--

*AB Experiments
--

* Field Experiments
--

* Natural Experiments

---
# Lab Experiments: Promise
--

* Avoids spurious correlations, questions of directionality
  * You control stimulus, when it happens, and how you measure outcomes.
* Randomization allows you to accurately estimate the ATE (*Average Treatment Effect*)
* People come in, you have them experience something, you then measure what happens after the fact.

---

# Lab Experiments: Pitfalls
--

* You are incredibly limited in what can be performed in a lab. 
* Lab work is stupid expensive.
* You have to be *very* deliberate and conscientious about **everything** because **_everything_** can mess with your results.
  * Everything has to be damn-near standardized per participant or else you fail to estimate the "true" ATE.
* Environment/stimulus/measurement is unnatural: It may not work outside in "reality" (It's easy to cure cancer in rats...)
* You can only get answers to the questions you ask. Nothing more. Nothing less.


---

# AB Experiments*: Promise
--

\* *We'll actually just lump this in with survey experiments*
--

* Can still avoid spurious correlations, questions of directionality--you, again, control the stimulus.
* Randomization still allows for the estimate of the ATE
* Much, **MUCH** cheaper to perform. 
* Better sense of "real world" effect (although still limited)
* Can be done anywhere! Can have some really precise effects due to the large samples that can be possible.

**Example: Facebook "I voted" experiment**
---
# AB Experiments: Pitfalls
--

* Still limited in what you can actually measure.
* This is way cheaper than lab experiments, but still not exactly cheap
* Bots. Lots of bots. So many bots.
* You don't know how much the participants paid attention.
* A lot more confounds have entered the equation.
---

# Field Experiment: Promise
--

* In addition to the ATE, spuriousness, etc...
* Even better sense of "real world" effect
* Often give much more immediate 
* Can often do a lot more (although not always).

**Example: "We'll rat you out to your neighbors" mailers.**

---
# Field Experiment: Pitfalls

* Doesn't mean you *should* do a lot more!!
* Attentiveness and roll-off are even **bigger** issues.  
* Super expensive (unless you can find a group willing to fund you.)
  * But then you have stakeholders to appease!
* Treatment efficacy is difficult to ascertain.

---

# Natural Experiment: Promise
--

* Acts of God/Nature/Chaos/Fortuna cause something to randomly happen to some group
  * Also see a lot of work exploiting edge cases around arbitrary rules: Which tend to be randomly associated.
* Measure the disjuncture between sudden events, assuming that things would have gone along, more or less, as they would have otherwise.
* ATE, supriousness, etc. etc.
* Hey, at least they're cheap to do.


# Natural Experiment: Pitfalls
--

* Most things you'd *think* are natural experiments are actually **not** natural experiments.
* You have to pay attention to the thing you're interested. *Really,* **REALLY** close attention (and you'll still miss things.)
* They aren't cheap to the people who *experience* them. You need to be ethical with the data born from human suffering. 

---
In sum, as with everything in Data/Social Science: Experiments are a balancing act. You have multiple competing considerations all at once.
